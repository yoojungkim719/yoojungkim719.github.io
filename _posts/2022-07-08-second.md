---
layout: single
title:  "실습예제"
---

## 독립적 앙상블 방법

- 독립적 앙상블 방법에서 사용하는 개별 분류기들은 서로 독립적인 알고리즘이므로 각 분류기는 서로 다른 머신러닝 알고리즘을 사용할 수도 있음
- 각 분류기가 독립적이므로 효과적으로 병렬화할 수 있음

## 배깅
- 개별 분류기들의 분류 결과를 종합하여 최종 분류기의 성능을 향상하는 방법
- 개별 분류기들이 동일한 트레이닝 데이터로 학습하는 보팅과는 달리 배깅은 오리지널 트레이닝 데이터 셋에서 부트스트랩 샘플을 뽑아 학습함 (부트스트랩이란 중복을 허용한 랜덤 샘플 방법임)
- 개별 분류 모형의 결과값을 모아 다수결 투표를 통해 최종 예측하게 됨
- 주로 배깅에 사용하는 개별 분류기들은 모두 같은 머신러닝 알고리즘

## 랜덤 포레스트
- 배깅을 이용한 가장 유명한 알고리즘
- 여러 개의 개별 분류기인 의사결정나무를 토대로 예측한 결과를 종합해 전체 예측 정확도를 높이는 방법
- 순서
    - n개의 데이터 랜덤 추출(중복 가능)
    - p개의 변수 선택(중복 불가능)
    - 의사결정나무 학습
    - 1)~3)을 반복
    - 각 의사결정나무 별 결과를 투표를 통해 클래스 레이블 설정


```python
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
```


```python
# 데이터 불러오기
raw_wine = datasets.load_wine()
```


```python
# 피처, 타깃 데이터 지정
x = raw_wine.data
y = raw_wine.target
```


```python
# 데이터 표준화
std_scale = StandardScaler()
std_scale.fit(x)
```




    StandardScaler()




```python
# 트레이닝/테스트 데이터 분할
x_tn, x_te, y_tn, y_te = train_test_split(x, y, random_state=0)
```


```python
# 학습
clf_rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)
# 100개의 decision tree를 생성
# max_depth: decision tree에서 최대 레벨
clf_rf.fit(x_tn, y_tn)
```




    RandomForestClassifier(max_depth=2, random_state=0)




```python
# 예측, 이렇게 되면 3개의 그룹으로 나뉜것 (0, 1, 2니까)
pred_rf = clf_rf.predict(x_te)
print(pred_rf)
```

    [0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 2 0 0 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0 2
     1 1 2 0 0 1 1 1]
    


```python
# 정확도 평가
accuracy = accuracy_score(y_te, pred_rf)
print(accuracy)
```

    0.9555555555555556
    


```python
# confusion matrix 확인
conf_matrix = confusion_matrix(y_te, pred_rf)
print(conf_matrix)
```

    [[16  0  0]
     [ 1 19  1]
     [ 0  0  8]]
    


```python
# 분류 리포트 확인
class_report = classification_report(y_te, pred_rf)
print(class_report)
```

                  precision    recall  f1-score   support
    
               0       0.94      1.00      0.97        16
               1       1.00      0.90      0.95        21
               2       0.89      1.00      0.94         8
    
        accuracy                           0.96        45
       macro avg       0.94      0.97      0.95        45
    weighted avg       0.96      0.96      0.96        45
    
    
